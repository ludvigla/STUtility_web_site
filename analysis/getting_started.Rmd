---
title: "Getting started"
date: ''
---

<style type="text/css">
div.main-container {
  background-color: #000000 !important;
  max-width: 1400px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<style>
#TOC {
  background: url("https://www.spatialresearch.org/wp-content/uploads/2019/09/str-logo-spatial_research_3@2x.png");
  background-size: contain;
  padding-top: 100px !important;
  background-repeat: no-repeat;
  op: 5%;
  opacity: 0.8;
  width: 500px;
  color: white;
  border-color: #000000 !important;
}
</style>

<style> code, pre{
  background-color: #000000 !important;
  color: white !important;
}
</style>
<style> 
body {
  color: white
}
</style>



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, autodep = TRUE)
```

First you need to load the library into your R session.

```{r load_lib}

library(STutility)

```

## 10X Visium platform

### Input files

10X Visium data output is produced with the [SpaceRanger](url). The output includes a number of files, but the ones that needs to be imported into R for STUtility is the following:

1. Count file (Count file with raw counts (UMI filtered) for each gene and capture spot. SpaceRanger outputs this in .h5 format, and the file is typically called "xxxxx_filtered_feature_bc_matrix.h5")
2. Position list (tissue_positions_list.txt for each sample, contains capture-spot barcode spatial information and pixel coordinates)
3. H&E image (tissue_hires_image.png or tissue_lowres_image.png for each sample)

Also, there is a forth file which holds information about the image scale:

4. scalefactors_json.json 

This file contains scaling factors subject to the H&E images of different resolutions. E.g.  "tissue_hires_scalef": 0.063, implies that the pixel coordinates in the position list should be scaled with 0.063 to match the size of the hires_image.png file. 

_In the current version of STUtility, this scaling factors needs to be noted manually and stated during the input when using the InputFromTable() function_ We have chosen this to minimize the number of dependencies. 

To use the full range of functions within STUtility, all three files are needed for each sample along with the information in the forth file. However, all data analysis steps that do not involve the H&E image can be performed with only the count file as input. To read in the 10x Visium .h5 files, the package `hdf5r` needs to be installed (`BiocManager::install("hdf5r")`).

---

To follow along this tutorial with a test data set, go to the [10x Dataset repo](https://support.10xgenomics.com/spatial-gene-expression/datasets) and download the following two files:

* Feature / cell matrix HDF5 (filtered)
* Spatial imaging data (.zip)
    * tissue_hires_image
    * tissue_positions_list
    * scalefactors_json

The .zip file contains the H&E image (in two resolution formats; "tissue_lowres_image" and "tissue_hires_image"), the "tissue_positions_list" with pixel coordinates for the orginial .tif image and the scalefactors_json.json that contains the scalefactors used to dervive the pixel cooridinates for the lowres and hires images. There are some alternatives to handle the scalefactors. Either, you manualy open the .json file and note the scalefactor used for the images you want to use (lowres or hires), and state these numbers in a column in the infoTable named "scaleVisium" (see below). Or, you add a column named "json" with paths to the "scalefactors_json.json" files. A third option is to manually input the values to the function InputFromTable (see `?InputFromTable`).

In this vignette we show e.g. the data sets from Mouse Brain Serial Section 1 and 2 (Sagittal-Posterior)

### Prepare data

The recommended method to read the files into R is via the creation of a "infoTable", there are three columns that the package will note whether they are included or not: "samples", "spotfiles" and "imgs". 
<br>
```{r example_infotable_Visium, echo=FALSE, eval=T}

samples <- c("Path to count file 1 ", "Path to count file 2")
spotfiles <- c("Path to position list  1", "Path to position list  2")
imgs <- c("Path to H&E image 1", "Path to H&E image 2")
scaleVisium <- c("scale to image 1", "scale to image 2")
data.frame(samples, spotfiles, imgs, scaleVisium)
```

These contains the paths to the files. Any number of _extra_ columns can be added with metadata. This information can then be used to e.g. coloring of plots and subsetting. These columns can be named as you like, but _not_ "sample", "spotfiles" or "imgs". Analysis of the data can be performed without the images, and then those columns are simply left out. 

Lets load the provided infoTable
<br>
```{r package_infotable_Visium, eval=F}

infoTable <- read.table("infoTable.csv", sep=",", header=T, stringsAsFactors = F)

```

We are now ready to load our samples and create a "seurat" object. 

Here, we demonstrate the creation of the seurat object, while also including some filtering: 

* Keeping the genes that are found in at least 5 capture spots and has a total count value >= 100. 
* Keeping the capture-spots that contains >= 500 total transcripts. 

Note that you have to specify which platform the data comes from. The default platform is 10X Visium but if you wish to run data from the older ST platforms, there is support for "1k" and "2k" arrays. You can also mix datasets from different platforms by specifying one of; "Visium", "1k" or "2k" in a separate column of the infoTable named "platform". You just have to make sure that the datasets have gene symbols which follows the same nomenclature.
<br>
```{r input_from_table_visium, eval=F}

se <- InputFromTable(infotable = infoTable, 
                      min.gene.count = 100, 
                      min.gene.spots = 5,
                      min.spot.count = 500,
                      platform="Visium")
```

```{r load_image_Visium, include=FALSE, eval=F}
se <- LoadImages(se, time.resolve=F)
```

```{r, pre-load, echo=F, eval=T}

load("~/STUtility/saved/preSaved_10x_serial.RData")

```
<br>
Once you have created a Seurat object you can process and visualize your data just like in a scRNA-seq experiment and make use of the plethora of functions provided in the Seurat package. There are many vignettes to get started available at the [Seurat web site](https://satijalab.org/seurat/vignettes.html).

For example, if you wish to explore the spatial distribution of various features on the array coordinates you can do this using the `ST.FeaturePlot()` function.
<br>


```{r, eval=TRUE, fig.width=14, fig.height=12, out.width='100%'}

ST.FeaturePlot(se, features = c("nFeature_RNA"), dark.theme = T, cols = c("black", "dark blue", "cyan", "yellow", "red", "dark red"))

```

<br>

## Original ST platform 

In general, using STUtility for the old ST platform data follows the same workflow as for the 10X Visium arrays. The only difference is when loading the data into R.

### Input files

The original ST workflow produces the following three output files:

1. Count file (Count file with raw counts (UMI filtered) for each gene and capture spot)
2. Spot detector output (File with spatial pixel coordinate information produces via the [Spot Detector webtool](https://github.com/SpatialTranscriptomicsResearch/st_spot_detector))
3. H&E image

### Prepare data

The recommended method to read the files into R is via the creation of a "infoTable", which is a table with at least three columns "samples", "spotfiles" and "imgs". 
<br>
```{r example_infotable, echo=FALSE, eval=F}

samples <- c("Path to count file 1 ", "Path to count file 2")
spotfiles <- c("Path to spotfile 1", "Path to spotfile 2")
imgs <- c("Path to H&E image 1", "Path to H&E image 2")
data.frame(samples, spotfiles, imgs)
```

Test data is provided:

```{r package_infotable, eval=F}

infoTable <- read.table("metaData_mmBrain.csv", sep=";", header=T, stringsAsFactors = F)[c(1, 5, 6, 7), ]

```

### Load data and convert from EnsambleIDs to gene symbols

The provided count matrices uses EnsambleIDs (with version id) for the gene names. Gene symbols are often a preference for easier reading, and we provide a transformation table accordingly. 
<br>
```{r annotation, cache = TRUE, eval=FALSE}
#Transformation table for geneIDs
ensids <- read.table(file = list.files(system.file("extdata", package = "STutility"), full.names = T, pattern = "mouse_genes"), header = T, sep = "\t", stringsAsFactors = F)

```

We are now ready to load our samples and create a "seurat" object. 

Here, we demonstrate the creation of the seurat object, while also including some filtering: 

* Keeping the genes that are found in at least 5 capture spots and has a total count value >= 100. 
* Keeping the capture-spots that contains >= 500 total transcripts. 

Note that we specify that we're using the "2k" array platform and also, since we in this case have genes in the columns, we set transpose=TRUE. 
<br>
```{r read_input_1, cache=F, eval=F}
#TODO: add warnings if ids missmatch. Check that ids are in the data.frame ...
se <- InputFromTable(infotable = infoTable, 
                      min.gene.count = 100, 
                      min.gene.spots = 5,
                      min.spot.count = 500, 
                      annotation = ensids, 
                      platform = "2k",
                      transpose = T,
                      pattern.remove = "^mt-")

```
<br>
Once you have created a Seurat object you can process and visualize your data just like in a scRNA-seq experiment and make use of the plethora of functions provided in the Seurat package. There are many vignettes to get started available at the [Seurat web site](https://satijalab.org/seurat/vignettes.html).

Some of the functionalities provided in the Seurat package are not yet supported by STUtility, such as dataset integration and multimodal analysis. These methods should in principle work if you treat the data like a scRNA-seq experiment, but you will not be able to make use of the image related data or the spatial visualization functions.

For example, if you wish to explore the spatial distribution of various features on the array coordinates you can do this using the `ST.FeaturePlot()` function.
<br>
```{r load_image, include=FALSE, eval=F}
se <- LoadImages(se, time.resolve=F)
```

```{r, pre-load_2k, echo=F, eval=T}

load("~/STUtility/saved/preSaved_2kHippo.RData")

```

```{r, eval=TRUE, fig.width=12, fig.height=10, out.width='100%'}

ST.FeaturePlot(se, features = c("nFeature_RNA"), dark.theme = T, cols = c("black", "dark blue", "cyan", "yellow", "red", "dark red"))

```
<br>

## Navigating and accessing data

Please look at the Seurat website for basic navigation of the Seurat object and how to access the different data transformations, dim.reductions etc. 
However, specific for STUtility, there is another S4 object stored within the Seurat objects "tool" slot, called "Staffli". This object contains all the STUtility specific meta data, like pixel cooridinates, sample IDs, platform types etc.

You can reach this via:

```{r}

head(se@tools$Staffli[[]])

```

This can be used to set Idents, subset the seurat object etc. 

In the next section we will show how you can load images into the Seurat object and how they can be manipulated to improve interpretability of you results.

&nbsp;
<hr />
<p style="text-align: center;">A work by <a href="j.bergenstrahle@scilifelab.se">Joseph Bergenstråhle</a> and <a href="ludvig.larsson@scilifelab.se">Ludvig Larsson</a></p>

<!-- Add icon library -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
    <a href="https://www.spatialresearch.org" class="fa fa-beer"></a>
</p>

&nbsp;
